{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Adding User Feedback to LLM Applications with Phoenix\n",
    "\n",
    "This tutorial demonstrates how to capture and analyze user feedback for LLM applications using Phoenix's tracing and annotation capabilities. We'll build a social media post generator that allows users to provide feedback on generated content.\n",
    "\n",
    "## Overview\n",
    "1. Set up Phoenix and OpenAI\n",
    "2. Create a post generator function\n",
    "3. Implement feedback mechanism\n",
    "4. Test the system\n",
    "5. Analyze feedback in Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix openai openinference-instrumentation-openai 'httpx<0.28'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Phoenix and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      " For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n",
      " Opening a view to the Phoenix app. The app is running at http://localhost:6006/\n",
      " OpenTelemetry Tracing Details \n",
      "|  Phoenix Project: social-media-post-generator\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Enter your OpenAI API key:  路路路路路路路路\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry import trace\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "\n",
    "# Configure Phoenix\n",
    "if \"PHOENIX_API_KEY\" in os.environ:\n",
    "    # If using cloud instance of Phoenix\n",
    "    os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.environ['PHOENIX_API_KEY']}\"\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\"\n",
    "else:\n",
    "    # Locally start an instance\n",
    "    import phoenix as px\n",
    "    px.launch_app().view()\n",
    "\n",
    "# Register tracer\n",
    "tracer_provider = register(project_name=\"social-media-post-generator\")\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "# Instrument OpenAI\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "\n",
    "# Initialize OpenAI client\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    from getpass import getpass\n",
    "    openai_api_key = getpass(\" Enter your OpenAI API key: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Post Generator and Feedback Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert social media content creator.\n",
    "Your task is to create a different promotion message with the following \n",
    "Product Description :\n",
    "------\n",
    "{product_desc}\n",
    "------\n",
    "The output promotion message should have the following :\n",
    "Title: a powerful, short message that dipict what this product is about \n",
    "Message: be creative for the promotion message, but make it short and ready for social media feeds, under 100 words.\n",
    "Tags: the hash tag human will nomally use in social media\n",
    "\n",
    "Give me the final post, do not have \"Title:\", \"Message:\", \"Tags:\" in it.\n",
    "Begin!\n",
    "\"\"\"\n",
    "\n",
    "def generate_post(description):\n",
    "    \"\"\"Generate a social media post with tracing\"\"\"\n",
    "    try:\n",
    "        attributes = {SpanAttributes.OPENINFERENCE_SPAN_KIND: \"CHAIN\"}\n",
    "        with tracer.start_as_current_span(\"Social media post\", attributes=attributes) as span:\n",
    "            span.set_attribute(SpanAttributes.INPUT_VALUE, description)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful social media content creator.\"},\n",
    "                    {\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(product_desc=description)}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            output_content = response.choices[0].message.content\n",
    "            span.set_attribute(SpanAttributes.OUTPUT_VALUE, output_content)\n",
    "            \n",
    "            span_context = span.get_span_context()\n",
    "            span_id = format(span_context.span_id, '016x')\n",
    "            \n",
    "            return output_content, span_id\n",
    "    except Exception as e:\n",
    "        return f\"Error generating post: {str(e)}\", None\n",
    "    \n",
    "\n",
    "def send_feedback_to_phoenix(span_id, feedback_type):\n",
    "    \"\"\"Send feedback annotation to Phoenix\"\"\"\n",
    "    if not span_id:\n",
    "        return False\n",
    "        \n",
    "    client = httpx.Client()\n",
    "    label = \"\" if feedback_type == \"like\" else \"\"\n",
    "    score = 1 if feedback_type == \"like\" else 0\n",
    "    \n",
    "    try:\n",
    "        annotation_payload = {\n",
    "            \"data\": [\n",
    "                {\n",
    "                    \"span_id\": span_id,\n",
    "                    \"name\": \"user feedback\",\n",
    "                    \"annotator_kind\": \"HUMAN\",\n",
    "                    \"result\": {\n",
    "                        \"label\": label, \n",
    "                        \"score\": score,\n",
    "                        \"explanation\": f\"User provided {feedback_type} feedback\"\n",
    "                    },\n",
    "                    \"metadata\": {}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        response = client.post(\n",
    "            \"http://localhost:6006/v1/span_annotations?sync=false\",\n",
    "            json=annotation_payload\n",
    "        )\n",
    "        return response.status_code == 200\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the System\n",
    "\n",
    "Let's test our post generator and feedback system with a sample product description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Post:\n",
      " Sip Sustainably, Live Refreshingly!\n",
      "\n",
      "Discover the EcoFresh Water Bottle: your new eco-friendly companion that keeps every sip perfectly cold for 24 hours or piping hot for 12. Crafted from recycled materials, this 32oz marvel features a sleek, leak-proof design in your favorite hues. Stay refreshed and reduce waste with every gulp. Eco-convenience never looked so good!\n",
      "\n",
      "#EcoFresh #HydrateResponsibly #SustainableLiving #StayCool #EcoFriendlyLiving #DrinkSmart #EarthLovers\n",
      "\n",
      "Span ID: 27df1f6642d34166\n"
     ]
    }
   ],
   "source": [
    "# Sample product description\n",
    "product_description = \"\"\"\n",
    "EcoFresh Water Bottle - A sustainable, insulated water bottle made from recycled materials.\n",
    "Keeps drinks cold for 24 hours or hot for 12 hours. Available in various colors.\n",
    "Features a leak-proof lid and carries 32oz of your favorite beverage.\n",
    "\"\"\"\n",
    "\n",
    "# Generate post\n",
    "generated_post, span_id = generate_post(product_description)\n",
    "print(\"Generated Post:\\n\", generated_post)\n",
    "print(\"\\nSpan ID:\", span_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Send Feedback\n",
    "\n",
    "Now let's simulate user feedback for the generated post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback sent successfully: True\n"
     ]
    }
   ],
   "source": [
    "# Send positive feedback\n",
    "success = send_feedback_to_phoenix(span_id, \"like\")\n",
    "print(f\"Feedback sent successfully: {success}\")\n",
    "\n",
    "# You can also try negative feedback\n",
    "# success = send_feedback_to_phoenix(span_id, \"dislike\")\n",
    "# print(f\"Feedback sent successfully: {success}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyzing Feedback in Phoenix\n",
    "\n",
    "Now that we've generated content and collected feedback, you can view the results in Phoenix:\n",
    "\n",
    "1. Open your Phoenix dashboard\n",
    "2. Navigate to the Traces view\n",
    "3. Look for traces with the name \"Social media post\"\n",
    "4. Click on a trace to see details including:\n",
    "   - Input product description\n",
    "   - Generated content\n",
    "   - User feedback ( or )\n",
    "   - Timing information\n",
    "\n",
    "This feedback data can help you:\n",
    "- Identify patterns in well-received vs poorly-received content\n",
    "- Monitor the quality of generated posts\n",
    "- Make data-driven improvements to your prompt engineering\n",
    "- Track user satisfaction over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
